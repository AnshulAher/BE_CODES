{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install tensorflow\n",
        "!pip install scikit-learn\n",
        "!pip install matplotlib"
      ],
      "metadata": {
        "id": "iJMenUjEr7AV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "E6d4pSivisev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load the dataset\n",
        "df = pd.read_csv('/content/IMDB Dataset.csv')"
      ],
      "metadata": {
        "id": "QJP78atyoSZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Encode sentiment labels to 0 and 1\n",
        "label_encoder = LabelEncoder()\n",
        "df['sentiment'] = label_encoder.fit_transform(df['sentiment'])"
      ],
      "metadata": {
        "id": "YOw5MfLtoaWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Define X (reviews) and y (labels)\n",
        "X = df['review'].values\n",
        "y = df['sentiment'].values"
      ],
      "metadata": {
        "id": "Jd3ANdo6oded"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Tokenization and padding\n",
        "vocab_size = 10000\n",
        "max_length = 200\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X)\n",
        "X_seq = tokenizer.texts_to_sequences(X)\n",
        "X_pad = pad_sequences(X_seq, maxlen=max_length, padding='post', truncating='post')"
      ],
      "metadata": {
        "id": "vUDXhwAeogtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "11y8N-qEoj9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Optimized Model (CNN + Dense)\n",
        "model = models.Sequential([\n",
        "    layers.Embedding(input_dim=vocab_size, output_dim=64, input_length=max_length),\n",
        "    layers.Conv1D(128, 5, activation='relu'),\n",
        "    layers.GlobalMaxPooling1D(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')  # Binary classification\n",
        "])"
      ],
      "metadata": {
        "id": "7tMiyIogonM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Efzjh8iropKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "BXeZ2SrgorjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Evaluate performance\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "id": "2elxlseSouDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Plot Accuracy\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SNu78LQ2ovtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 11: Predict sentiment from user review\n",
        "def predict_review(review_text):\n",
        "    sequence = tokenizer.texts_to_sequences([review_text])\n",
        "    padded = pad_sequences(sequence, maxlen=max_length, padding='post', truncating='post')\n",
        "    prediction = model.predict(padded)[0][0]\n",
        "    sentiment = \"Positive\" if prediction >= 0.5 else \"Negative\"\n",
        "    print(f\"Predicted Sentiment: {sentiment}\")"
      ],
      "metadata": {
        "id": "ZMkaWkBCox36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 12: Take input and predict\n",
        "user_review = input(\"Enter a movie review: \")\n",
        "predict_review(user_review)"
      ],
      "metadata": {
        "id": "o2fZ8eYoivKS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}